"""Processing and analysis of fluorescence spectra."""

from __future__ import annotations

import numpy as np
from numba import njit, prange
from jacobi import propagate
from matplotlib import gridspec
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt
import h5py


from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from typing import Literal
    from matplotlib.axes import Axes
    from matplotlib.figure import Figure
    from numpy.typing import ArrayLike, NDArray
    from agepy.spec.photons.anodes import PositionAnode

    type RegionOfInterest = tuple[tuple[float, float], tuple[float, float]]
    type QuantumEfficiency = tuple[NDArray, NDArray, NDArray]
    type WavelengthCalib = tuple[tuple[float, float], tuple[float, float]]
    type ErrorPropagation = Literal["montecarlo", "none"]


class Spectrum:
    """Fluorescence spectrum."""

    def __init__(
        self,
        xy: NDArray,
        time: int | None = None,
        **norm: str,
    ) -> None:
        """Initialize an instance of the Spectrum class from a 2D array
        containing x and y values of photon hits.

        In most cases it is recommended to use the `from_h5` class method
        to load the data from an h5 file generated by metro2hdf.

        Parameters
        ----------
        xy: NDArray
            2D array containing x and y values of photon hits.
        time: int, optional
            Measurement time in seconds for normalization. Default: None.
        **norm
            Additional normalization parameters as keyword arguments
            like the upstream intensity or target density. The values
            can be either floats or 1D arrays containing the value and
            its uncertainty.

        """
        # Store the passed data
        self._xy = xy
        self._t = time
        self._norm = list(norm.keys())
        for key, value in norm.items():
            setattr(self, key, value)

    @classmethod
    def from_h5(
        cls,
        file_path: str,
        anode: PositionAnode,
        raw: str = "dld_rd#raw",
        time: int | None = None,
        **norm: str,
    ) -> Spectrum:
        """Load a Spectrum from an h5 file generated by metro2hdf.

        Parameters
        ----------
        file_path: str
            Path to the h5 file.
        anode: PositionAnode
            Anode object to process the raw data.
        raw: str, optional
            Path to the raw data in the h5 file. Default:
            "dld_rd#raw".
        time: int, optional
            Measurement time in seconds for normalization. Default: None.
        **norm
            Additional normalization parameters as keyword arguments
            like `intensity_upstream` or `target_density`.

        Returns
        -------
        Spectrum
            The created Spectrum object.

        """
        with h5py.File(file_path, "r") as h5:
            # Load the raw data
            raw = np.asarray(h5[raw + "/0/0.0"])

            # Load normalization values
            for key, h5path in norm.items():
                if h5path not in h5:
                    raise ValueError("Normalization parameter not found.")

                if h5path.endswith("avg"):
                    norm[key] = h5[h5path + "/0"][0]

                else:
                    values = np.asarray(h5[h5path + "/0/0.0"])
                    norm[key] = np.array(
                        [np.mean(values), np.std(values)]
                    ).flatten()

        # Initialize the Spectrum
        return cls(anode.process(raw), time=time, **norm)

    def xy(self) -> tuple[NDArray, NDArray]:
        """Get the detector image of the spectrum.

        Returns
        -------
        np.ndarray
            The x and y values of the photon hits.

        """
        return self._xy[:, 0], self._xy[:, 1]

    def det_image(
        self,
        bins: ArrayLike | tuple[ArrayLike, ArrayLike] | None = None,
        x_lim: tuple[float, float] = (0, 1),
        y_lim: tuple[float, float] = (0, 1),
        figsize: tuple[float, float] = (6, 6),
        num: str | int | None = None,
        fig: Figure | None = None,
        ax: tuple[Axes, Axes, Axes, Axes] | None = None,
    ) -> tuple[Figure, Axes]:
        """Plot the detector image of the spectrum."""
        # Create the figure
        if fig is None or ax is None:
            fig = plt.figure(num=num, figsize=figsize, clear=True)

            # grid with columns=2, row=2
            gs = gridspec.GridSpec(
                2,
                2,
                width_ratios=[3, 1],
                height_ratios=[1, 3],
                wspace=0.05,
                hspace=0.05,
            )

            # 2d detector image is subplot 2: lower left
            ax_det = plt.subplot(gs[2])

            # x projection is subplot 0: upper left
            ax_x = plt.subplot(gs[0], sharex=ax_det)

            # y projection is subplot 3: lower right
            ax_y = plt.subplot(gs[3], sharey=ax_det)

            # colorbar is subplot 1: upper right
            ax_cb = plt.subplot(gs[1])
            ax_cb.axis("off")
            ax_cb_inset = ax_cb.inset_axes([0.0, 0.0, 0.25, 1.0])

            # Remove x and y tick labels
            ax_x.tick_params(axis="both", labelbottom=False)
            ax_y.tick_params(axis="both", labelleft=False)

            # Remove grid from the detector image and colorbar
            ax_det.grid(False)
            ax_cb_inset.grid(False)

        else:
            try:
                ax_det, ax_x, ax_y, ax_cb_inset = ax

                ax_det.clear()
                ax_x.clear()
                ax_y.clear()
                ax_cb_inset.clear()

            except Exception as e:
                raise ValueError("Invalid axes sequence provided.") from e

        # Get the data
        x, y = self.xy()

        if bins is None:
            # Define x and y edges
            bins = np.histogram([], bins=512, range=(0, 1))[1]

        # Histogram the data
        hist_xy, x_edges, y_edges = np.histogram2d(x, y, bins=bins)

        # Define a meshgrid
        x_mesh, y_mesh = np.meshgrid(x_edges, y_edges)

        # Get a colormap from matplotlib
        cmap = plt.get_cmap("YlOrBr_r")

        # Get color for the projections
        color = cmap(0)

        # Set the lowest value to white
        colors = cmap(np.linspace(0, 1, cmap.N))
        colors[0] = (1, 1, 1, 1)

        # Create a colormap with white as the lowest value
        cmap = mcolors.ListedColormap(colors)

        # Plot the detector image
        pcm = ax_det.pcolormesh(
            x_mesh, y_mesh, hist_xy.T, cmap=cmap, rasterized=True
        )

        # Create a colorbar
        fig.colorbar(pcm, cax=ax_cb_inset)

        # Project the detector image onto the x and y axes
        hist_x = np.histogram(x, bins=x_edges)[0]
        hist_y = np.histogram(y, bins=y_edges)[0]

        # Plot the x and y projections
        ax_x.stairs(hist_x, x_edges, color=color)
        ax_y.stairs(hist_y, y_edges, color=color, orientation="horizontal")

        # Remove the first tick label of the x and y projection
        plt.setp(ax_x.get_yticklabels()[0], visible=False)
        plt.setp(ax_y.get_xticklabels()[0], visible=False)

        # Set the limits (this changes the positon of ax_det)
        ax_det.set_xlim(x_lim)
        ax_x.set_xlim(x_lim)
        ax_det.set_ylim(y_lim)
        ax_y.set_ylim(y_lim)

        # Set the labels
        ax_det.set_xlabel("x [arb. u.]")
        ax_det.set_ylabel("y [arb. u.]")

        return fig, (ax_det, ax_x, ax_y, ax_cb_inset)

    def counts(
        self,
        roi: RegionOfInterest | None = None,
        qeff: QuantumEfficiency | None = None,
        bkg: Spectrum | float | None = None,
    ) -> tuple[float, float]:
        """Get the number of counts in the spectrum and the estimated
        uncertainty.

        Parameters
        ----------
        roi: Tuple[Tuple[float, float], Tuple[float, float]], optional
            Region of interest for the detector in the form
            `((xmin, xmax), (ymin, ymax))`. If not provided, the
            full detector is used.
        qeff: Tuple[np.ndarray, np.ndarray, np.ndarray], optional
            Detector efficiencies in the form `(values, errors, x)`.
        bkg: Union[Spectrum, np.ndarray], optional
            Background spectrum (dark counts) to be subtracted that can
            be provided either as an instance of `Spectrum` or as an
            array of the length `len(edges) - 1`. For this to work
            properly, the background spectrum must be normalized to
            its measurement duration.

        Returns
        -------
        Tuple[float, float]
            The number of counts (normalized) and the respective
            uncertainty.

        """
        data = np.copy(self._xy)

        # Use the full detector if roi not provided
        if roi is not None:
            # Apply y roi filter
            data = data[data[:, 1] > roi[1][0]]
            data = data[data[:, 1] < roi[1][1]]
            # Discard y values
            data = data[:, 0].flatten()
            # Apply x roi filter
            data = data[data > roi[0][0]]
            data = data[data < roi[0][1]]

        # Apply spatial detector efficiency correction
        if qeff is not None:
            eff_val, eff_err, eff_x = qeff
            xedges = (eff_x[:-1] + eff_x[1:]) * 0.5
            eff_inds = np.digitize(data, xedges)

            def sum_weights(eff):
                return np.sum(1 / eff[eff_inds])

            # Sum the efficiencies and propagate the uncertainties
            counts, error = propagate(sum_weights, eff_val, eff_err**2)
            error = np.sqrt(np.diag(error))[0]

            # Include the Poisson uncertainties
            error = np.sqrt(len(data) + error**2)

        else:
            # Calculate the number of counts and the Poisson uncertainty
            counts = len(data)
            error = np.sqrt(counts)

        # Normalize data to measurement duration
        if self._t is not None:
            counts /= self._t
            error /= self._t

        # Subtract background before further normalization
        if isinstance(bkg, Spectrum):
            bkg_counts, bkg_err = bkg.counts(roi=roi, qeff=qeff, bkg=None)
            # Using just the statistical uncertainty of the background
            # counts would underestimate the uncertainty of the subtraction
            bkg_err = np.sqrt(bkg_counts * self._t) / self._t
            counts = max(counts - bkg_counts, 0)
            error = np.sqrt(error**2 + bkg_err**2)

        # Normalize data to account for beam intensity, gas
        # pressure, etc.
        for normalize in self._norm:
            if isinstance(getattr(self, normalize), np.ndarray):
                val, err = getattr(self, normalize)
                error = np.sqrt(
                    error**2 / val**2 + err**2 * counts**2 / val**4
                )
                counts /= val
            else:
                counts /= getattr(self, normalize)
                error /= getattr(self, normalize)

        # Return the counts and the uncertainty
        return counts, error

    def spectrum(
        self,
        edges: NDArray,
        roi: RegionOfInterest | None = None,
        qeff: QuantumEfficiency | None = None,
        bkg: Spectrum | NDArray | None = None,
        calib: WavelengthCalib | None = None,
        err_prop: ErrorPropagation = "montecarlo",
        mc_samples: int = 10000,
    ) -> tuple[NDArray, NDArray]:
        """Calculate the spectum and its uncertainties for a given
        set of bin edges.

        Parameters
        ----------
        edges: np.ndarray
            Bin edges for the histogram. For a calibrated spectrum,
            these should be in wavelength units. For an uncalibrated
            spectrum, these should be between 0 and 1.
        roi: Tuple[Tuple[float, float], Tuple[float, float]], optional
            Region of interest for the detector in the form
            `((xmin, xmax), (ymin, ymax))`. If not provided, the
            full detector is used.
        qeff: Tuple[np.ndarray, np.ndarray, np.ndarray], optional
            Detector efficiencies in the form `(values, errors, x)`.
            The efficiencies are interpolated to 512 points between
            0 and 1.
        bkg: Union[Spectrum, np.ndarray], optional
            Background spectrum (dark counts) to be subtracted that can
            be provided either as an instance of `Spectrum` or as an
            array of the length `len(edges) - 1`. For this to work
            properly, the background spectrum must be normalized to
            its measurement duration.
        calib: Tuple[Tuple[float, float], Tuple[float, float]], optional
            Wavelength calibration parameters in the form
            `((a0, err), (a1, err))`, where `a0` and `a1`
            correspond to wavelength = a1 * x + a0 and `err` to the
            respective uncertainties.
        err_prop: Literal["jacobi", "montecarlo", "none"], optional
            Error propagation method for handling the uncertainties of
            the efficiencies and the wavelength calibration. If
            `qeff = None` and `calib = None`, this setting has no
            effect. Can be 'montecarlo', or 'none'.
        mc_samples: int, optional
            Number of Monte Carlo samples to use for error propagation.
            Has no effect if `err_prop = 'none'`.

        Returns
        -------
        Tuple[NDArray, NDArray]
            The spectrum and its uncertainties.

        """
        # Get x and y values of the photon hits
        data = np.copy(self._xy)

        # Define the roi as the full detector if not provided
        if roi is None:
            roi = ((0, 1), (0, 1))

        # Apply y roi filter
        data = data[data[:, 1] > roi[1][0]]
        data = data[data[:, 1] < roi[1][1]]

        # Don't need y values anymore
        data = data[:, 0].flatten()

        # Prepare the background subtraction
        if isinstance(bkg, Spectrum):
            # Get the measurement duration of the background
            bkg_t = bkg._t
            # Test if background and data both have a time value
            if bkg_t is None or self._t is None:
                raise ValueError(
                    "Both background and data must have a time value."
                )

            # Get the x and y values of the background spectrum
            bkg_data = bkg._xy

            # Apply y roi filter
            bkg_data = bkg_data[bkg_data[:, 1] > roi[1][0]]
            bkg_data = bkg_data[bkg_data[:, 1] < roi[1][1]]

            # Don't need y values anymore
            bkg_data = bkg_data[:, 0].flatten()

            # Prepare the background to be passed to the spectrum calculation
            bkg = (bkg_data, bkg_t)

        else:
            # Continue without background subtraction
            bkg = None

        # Prepare the wavelength calibration parameters
        if calib is not None:
            try:
                calib_params = np.array(calib, dtype=np.float64)
                assert calib_params.shape == (2, 2)

            except Exception as e:
                errmsg = "calib must be provided as ((a0, err), (a1, err))."
                raise ValueError(errmsg) from e

            # Adjust x roi filter to wavelength binning
            wl_min = calib_params[1][0] * roi[0][0] + calib_params[0][0]
            wl_max = calib_params[1][0] * roi[0][1] + calib_params[0][0]
            roi = np.argwhere((edges < wl_min) | (edges > wl_max)).flatten()

        else:
            # Define dummy calibration parameters
            calib_params = np.array([[0, 0], [1, 0]])

            # Adjust x roi filter to binning
            roi = np.argwhere(
                (edges < roi[0][0]) | (edges > roi[0][1])
            ).flatten()

        # Prepare spatial detector efficiency correction
        if qeff is not None:
            try:
                # Test if the efficiencies are provided correctly
                qeff_val = np.array(qeff[0])
                qeff_err = np.array(qeff[1])
                qeff_x = np.array(qeff[2])
                assert len(qeff_val) == len(qeff_err)
                assert len(qeff_val) == len(qeff_x)

            except Exception as e:
                errmsg = "qeff must be provided as (values, errors, x)."
                raise ValueError(errmsg) from e

            qeff = (qeff_val, qeff_err, qeff_x)

        if calib is None and qeff is None and bkg is None:
            spectrum = np.histogram(data, bins=edges)[0]
            spectrum = np.array(spectrum, dtype=np.float64)
            errors = np.sqrt(spectrum)

        elif err_prop == "montecarlo":
            # Initialize the random number generator
            rng = np.random.default_rng()

            # Initialize array for storing the sample results
            spectrum = np.zeros((mc_samples, len(edges) - 1), dtype=np.float64)

            # Perform the Monte Carlo simulation
            if qeff is None and bkg is None:
                spectrum = _mc_calibrated_spectrum(
                    spectrum, data, edges, calib_params, rng, mc_samples
                )
            elif qeff is None:
                spectrum = _mc_calibrated_spectrum_with_bkg(
                    spectrum,
                    (data, self._t),
                    edges,
                    bkg,
                    calib_params,
                    rng,
                    mc_samples,
                )
            elif bkg is None:
                spectrum = _mc_calibrated_spectrum_with_qeff(
                    spectrum, data, edges, qeff, calib_params, rng, mc_samples
                )
            else:
                spectrum = _mc_calibrated_spectrum_with_bkg_qeff(
                    spectrum,
                    (data, self._t),
                    edges,
                    bkg,
                    qeff,
                    calib_params,
                    rng,
                    mc_samples,
                )

            # Calculate mean and standard deviation of the sampled spectra
            errors = np.std(spectrum, ddof=1, axis=0)
            spectrum = np.mean(spectrum, axis=0)

        elif err_prop == "none":
            # Calibrate the data
            if calib is not None:
                data = calib_params[1][0] * data + calib_params[0][0]

            # Histogram the data without the efficiencies
            spectrum = np.histogram(data, bins=edges)[0]
            errors = np.sqrt(spectrum)

            # Interpolate and assign the efficiencies
            if qeff is not None:
                xedges = np.linspace(0, 1, 513)
                xvalues = (xedges[1:] + xedges[:-1]) * 0.5
                qeff = np.interp(xvalues, qeff[2], qeff[0])
                eff_inds = np.digitize(data, xedges[1:-1])
                qeff = 1 / qeff[eff_inds]

                # Histogram the data with the efficiencies
                weights = np.histogram(data, bins=edges, weights=qeff)[0]

                # Calculate the uncertainties
                nonzero = spectrum > 0
                errors[nonzero] = weights[nonzero] * np.sqrt(
                    2 / spectrum[nonzero]
                )
                spectrum = weights

            if bkg is not None:
                # Calibrate the background data
                if calib is not None:
                    bkg_data = (
                        calib_params[1][0] * bkg_data + calib_params[0][0]
                    )

                # Histogram the background data
                if qeff is not None:
                    # Interpolate and assign the efficiencies
                    bkg_inds = np.digitize(bkg_data, xedges[1:-1])
                    bkg_qeff = 1 / qeff[bkg_inds]

                    # Histogram the background data with the efficiencies
                    bkg = np.histogram(bkg_data, bins=edges, weights=bkg_qeff)[
                        0
                    ]

                else:
                    # Histogram the background data without the efficiencies
                    bkg = np.histogram(bkg_data, bins=edges)[0]

                # Convert to floats
                bkg = np.array(bkg, dtype=np.float64)

                # Normalize the background to the measurement duration
                bkg = bkg / bkg_t * self._t

                # Subtract the background
                spectrum -= bkg
                spectrum[spectrum < 0] = 0

        else:
            errmsg = "Error propagation method must be 'montecarlo' or 'none'."
            raise ValueError(errmsg)

        # Normalize data to measurement duration per step
        if self._t is not None:
            spectrum /= self._t
            errors /= self._t

        # Normalize data to account for beam intensity, gas
        # pressure, etc.
        for normalize in self._norm:
            if isinstance(getattr(self, normalize), np.ndarray):
                val, err = getattr(self, normalize)
                errors = np.sqrt(
                    errors**2 / val**2 + err**2 * spectrum**2 / val**4
                )
                spectrum /= val
            else:
                spectrum /= getattr(self, normalize)
                errors /= getattr(self, normalize)

        # Apply x roi filter
        spectrum[roi[:-1]] = 0
        errors[roi[:-1]] = 0

        # Return the spectrum and uncertainties
        return spectrum, errors

    def transform_norm(self, norm: str, func: callable) -> None:
        """Transform the specified normalization values using a given
        function.

        Parameters
        ----------
        norm: str
            Name of the normalization parameter to transform.
        func: callable
            Function to apply to the normalization values. The function
            should take a single argument of type float and return a
            float.

        """
        val = getattr(self, norm)

        if isinstance(val, np.ndarray):
            val, err = propagate(func, val[0], val[1] ** 2)
            setattr(self, norm, np.array([val, np.sqrt(err)]))

        else:
            setattr(self, norm, func(val))

    def convert_unit(self, norm: str, fro: str, to: str) -> None:
        """Convert the specified normalization values to a different
        unit using the pint package.

        Parameters
        ----------
        norm: str
            Name of the normalization parameter to convert.
        fro: str
            Unit to convert from.
        to: str
            Unit to convert to.

        """
        try:
            from pint import UnitRegistry

        except ImportError as e:
            raise ImportError("pint is required to convert units.") from e

        ureg = UnitRegistry()
        # Convert the normalization values
        self.transform_norm(norm, lambda x: ureg.Quantity(x, fro).m_as(to))


@njit()
def compute_bin(x: float, bin_edges: NDArray) -> int:
    # assuming uniform bins
    n = bin_edges.shape[0] - 1
    a_min = bin_edges[0]
    a_max = bin_edges[-1]

    # special case to mirror NumPy behavior for last bin
    if x == a_max:
        return n - 1  # a_max always in last bin

    bin_idx = int(n * (x - a_min) / (a_max - a_min))

    if bin_idx < 0 or bin_idx >= n:
        return None

    else:
        return bin_idx


@njit()
def numba_histogram(data: NDArray, bin_edges: NDArray) -> NDArray:
    hist = np.zeros((bin_edges.shape[0] - 1,), dtype=np.float64)

    for x in data.flat:
        bin_idx = compute_bin(x, bin_edges)
        if bin_idx is not None:
            hist[int(bin_idx)] += 1

    return hist


@njit()
def numba_weighted_histogram(
    data: NDArray,
    bin_edges: NDArray,
    weights: NDArray,
) -> NDArray:
    hist = np.zeros((bin_edges.shape[0] - 1,), dtype=np.float64)

    for x, w in zip(data.flat, weights.flat):
        bin_idx = compute_bin(x, bin_edges)
        if bin is not None:
            hist[int(bin_idx)] += w

    return hist


@njit(parallel=True)
def _mc_calibrated_spectrum(output, data, edges, calib, rng, n):
    # Determine number of measured data points
    data_counts = len(data)

    # Start the Monte Carlo simulation
    for i in prange(n):
        # Select data points based on Poisson sampling
        p = rng.poisson(lam=data_counts, size=1)[0]
        poisson_inds = rng.integers(0, data_counts, size=p)
        data_sample = data[poisson_inds]
        # Convert x values to wavelengths
        a0_sample = rng.normal(calib[0][0], calib[0][1], size=1)[0]
        a1_sample = rng.normal(calib[1][0], calib[1][1], size=1)[0]
        data_sample = a1_sample * data_sample + a0_sample
        # Calculate the sum of weights for each bin, i.e. the weighted spectrum
        output[i] = numba_histogram(data_sample, edges)

    # Return the n generated Monte Carlo spectra
    return output


@njit(parallel=True)
def _mc_calibrated_spectrum_with_qeff(
    output, data, edges, qeff, calib, rng, n
):
    # Prepare the quantum efficiency correction
    n_eff = len(qeff[0])
    # Define the interpolation grid for the efficiencies
    xedges = np.linspace(0, 1, 513)
    xvalues = (xedges[1:] + xedges[:-1]) * 0.5
    # Assign the efficiencies to the data points
    eff_inds = np.digitize(data, xedges[1:-1])

    # Determine number of measured data points
    data_counts = len(data)

    # Start the Monte Carlo simulation
    for i in prange(n):
        # Create a sample of the efficiencies
        eff_sample = np.ones(n_eff)
        for j in range(n_eff):
            eff_sample[j] = rng.normal(qeff[0][j], qeff[1][j], size=1)[0]
        # Interpolate the efficiencies to get a smoother spectrum
        eff_sample = np.interp(xvalues, qeff[2], eff_sample)
        # Get the efficiencies for each point
        data_eff = 1 / eff_sample[eff_inds]
        # Select data points based on Poisson sampling
        p = rng.poisson(lam=data_counts, size=1)[0]
        poisson_inds = rng.integers(0, data_counts, size=p)
        data_sample = data[poisson_inds]
        data_eff = data_eff[poisson_inds]
        # Convert x values to wavelengths
        a0_sample = rng.normal(calib[0][0], calib[0][1], size=1)[0]
        a1_sample = rng.normal(calib[1][0], calib[1][1], size=1)[0]
        data_sample = a1_sample * data_sample + a0_sample
        # Calculate the sum of weights for each bin, i.e. the weighted spectrum
        output[i] = numba_weighted_histogram(data_sample, edges, data_eff)

    # Return the n generated Monte Carlo spectra
    return output


@njit(parallel=True)
def _mc_calibrated_spectrum_with_bkg(output, data, edges, bkg, calib, rng, n):
    # Determine number of measured data points
    data_counts = len(data[0])
    # Determine the number of background data points to draw
    bkg_sample_size = int(len(bkg[0]) / bkg[1] * data[1])
    # Define the edges for the background distribution
    xedges = np.linspace(0, 1, 513)
    # Calculate the background distribution
    bkg_pdf = numba_histogram(bkg[0], xedges)
    # Assign the background probabilities to the data points
    bkg_inds = np.digitize(data[0], xedges[1:-1])
    bkg_prob = bkg_pdf[bkg_inds]

    # Start the Monte Carlo simulation
    for i in prange(n):
        # Select data points based on Poisson sampling
        p = rng.poisson(lam=data_counts, size=1)[0]
        poisson_inds = rng.integers(0, data_counts, size=p)
        data_sample = data[0][poisson_inds]
        bkg_sample = bkg_prob[poisson_inds]
        # Remove data points based on the background distribution
        p = rng.poisson(lam=bkg_sample_size, size=1)[0]
        bkg_cdf = np.cumsum(bkg_sample)
        remove_inds = np.searchsorted(bkg_cdf, rng.random(p) * bkg_cdf[-1])
        data_sample = np.delete(data_sample, remove_inds)
        # Convert x values to wavelengths
        a0_sample = rng.normal(calib[0][0], calib[0][1], size=1)[0]
        a1_sample = rng.normal(calib[1][0], calib[1][1], size=1)[0]
        data_sample = a1_sample * data_sample + a0_sample
        # Calculate the sum of weights for each bin, i.e. the weighted spectrum
        output[i] = numba_histogram(data_sample, edges)

    # Return the n generated Monte Carlo spectra
    return output


@njit(parallel=True)
def _mc_calibrated_spectrum_with_bkg_qeff(
    output, data, edges, bkg, qeff, calib, rng, n
):
    # Prepare the quantum efficiency correction
    n_eff = len(qeff[0])
    # Define the interpolation grid for the efficiencies
    xedges = np.linspace(0, 1, 513)
    xvalues = (xedges[1:] + xedges[:-1]) * 0.5
    # Assign the efficiencies to the data points
    eff_inds = np.digitize(data[0], xedges[1:-1])

    # Determine number of measured data points
    data_counts = len(data[0])
    # Determine the number of background data points to draw
    bkg_sample_size = int(len(bkg[0]) / bkg[1] * data[1])
    # Calculate the background distribution
    bkg_pdf = numba_histogram(bkg[0], xedges)
    # Assign the background probabilities to the data points
    bkg_prob = bkg_pdf[eff_inds]

    # Start the Monte Carlo simulation
    for i in prange(n):
        # Create a sample of the efficiencies
        eff_sample = np.ones(n_eff)
        for j in range(n_eff):
            eff_sample[j] = rng.normal(qeff[0][j], qeff[1][j], size=1)[0]
        # Interpolate the efficiencies to get a smoother spectrum
        eff_sample = np.interp(xvalues, qeff[2], eff_sample)
        # Get the efficiencies for each point
        data_eff = 1 / eff_sample[eff_inds]
        # Select data points based on Poisson sampling
        p = rng.poisson(lam=data_counts, size=1)[0]
        poisson_inds = rng.integers(0, data_counts, size=p)
        data_sample = data[0][poisson_inds]
        data_eff = data_eff[poisson_inds]
        bkg_sample = bkg_prob[poisson_inds]
        # Remove data points based on the background distribution
        p = rng.poisson(lam=bkg_sample_size, size=1)[0]
        bkg_cdf = np.cumsum(bkg_sample)
        remove_inds = np.searchsorted(bkg_cdf, rng.random(p) * bkg_cdf[-1])
        data_sample = np.delete(data_sample, remove_inds)
        data_eff = np.delete(data_eff, remove_inds)
        # Convert x values to wavelengths
        a0_sample = rng.normal(calib[0][0], calib[0][1], size=1)[0]
        a1_sample = rng.normal(calib[1][0], calib[1][1], size=1)[0]
        data_sample = a1_sample * data_sample + a0_sample
        # Calculate the sum of weights for each bin, i.e. the weighted spectrum
        output[i] = numba_weighted_histogram(data_sample, edges, data_eff)

    # Return the n generated Monte Carlo spectra
    return output
